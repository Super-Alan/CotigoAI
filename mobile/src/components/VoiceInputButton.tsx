/**
 * è¯­éŸ³è¾“å…¥æŒ‰é’®ç»„ä»¶
 *
 * åŠŸèƒ½ï¼š
 * 1. é•¿æŒ‰å¼€å§‹å½•éŸ³ï¼Œæ¾å¼€ç»“æŸå½•éŸ³
 * 2. å®æ—¶æ˜¾ç¤ºå½•éŸ³çŠ¶æ€å’Œæ³¢å½¢åŠ¨ç”»
 * 3. æ˜¾ç¤ºè¯†åˆ«ç»“æœ
 * 4. æ”¯æŒå–æ¶ˆå½•éŸ³ï¼ˆæ»‘å‡ºèŒƒå›´ï¼‰
 */

import React, { useState, useRef, useEffect } from 'react';
import {
  View,
  Text,
  TouchableOpacity,
  Animated,
  StyleSheet,
  Alert,
  PanResponder,
  Dimensions,
} from 'react-native';
import { SpeechRecognitionService, RecognitionEvent, RecordingState } from '@/src/services/speech.service';

const SCREEN_WIDTH = Dimensions.get('window').width;
const CANCEL_THRESHOLD = 80; // ä¸Šæ»‘è¶…è¿‡æ­¤è·ç¦»å–æ¶ˆå½•éŸ³

interface VoiceInputButtonProps {
  apiKey: string;
  onResult: (text: string) => void; // è¯†åˆ«å®Œæˆå›è°ƒ
  disabled?: boolean;
}

export function VoiceInputButton({ apiKey, onResult, disabled }: VoiceInputButtonProps) {
  const [recordingState, setRecordingState] = useState<RecordingState>('idle');
  const [recognizedText, setRecognizedText] = useState(''); // ç´¯ç§¯çš„è¯†åˆ«æ–‡æœ¬
  const [tempText, setTempText] = useState(''); // ä¸´æ—¶æ–‡æœ¬ï¼ˆä¸­é—´ç»“æœï¼‰
  const [finalText, setFinalText] = useState(''); // ç¡®è®¤æ–‡æœ¬ï¼ˆæœ€ç»ˆç»“æœï¼‰
  const [isCancelling, setIsCancelling] = useState(false);

  const speechService = useRef<SpeechRecognitionService | null>(null);
  const scaleAnim = useRef(new Animated.Value(1)).current;
  const pulseAnim = useRef(new Animated.Value(1)).current;
  const slideAnim = useRef(new Animated.Value(0)).current;

  // åˆå§‹åŒ–è¯­éŸ³æœåŠ¡
  useEffect(() => {
    speechService.current = new SpeechRecognitionService({
      apiKey,
    });

    return () => {
      if (speechService.current) {
        speechService.current.destroy();
      }
    };
  }, [apiKey]);

  // å½•éŸ³æ—¶çš„è„‰å†²åŠ¨ç”»
  useEffect(() => {
    if (recordingState === 'recording') {
      Animated.loop(
        Animated.sequence([
          Animated.timing(pulseAnim, {
            toValue: 1.2,
            duration: 600,
            useNativeDriver: true,
          }),
          Animated.timing(pulseAnim, {
            toValue: 1,
            duration: 600,
            useNativeDriver: true,
          }),
        ])
      ).start();
    } else {
      pulseAnim.setValue(1);
    }
  }, [recordingState]);

  // å¤„ç†è¯†åˆ«äº‹ä»¶
  const handleRecognitionEvent = (event: RecognitionEvent) => {
    console.log('[VoiceInput] Event:', event.type, event.text, 'isFinal:', event.isFinal);

    switch (event.type) {
      case 'task-started':
        setRecordingState('recording');
        setTempText('');
        setFinalText('');
        setRecognizedText('');
        break;

      case 'result-generated':
        if (event.text) {
          if (event.isFinal) {
            // æœ€ç»ˆç»“æœï¼šç´¯åŠ åˆ°ç¡®è®¤æ–‡æœ¬
            setFinalText(prev => prev + event.text);
            setTempText(''); // æ¸…ç©ºä¸´æ—¶æ–‡æœ¬
            console.log('[VoiceInput] Final result:', event.text);
          } else {
            // ä¸­é—´ç»“æœï¼šæ˜¾ç¤ºåœ¨ä¸´æ—¶æ–‡æœ¬
            setTempText(event.text);
            console.log('[VoiceInput] Temp result:', event.text);
          }
          // æ›´æ–°æ€»æ–‡æœ¬ç”¨äºæœ€åè¿”å›
          setRecognizedText(finalText + (event.isFinal ? event.text : '') + (event.isFinal ? '' : tempText));
        }
        break;

      case 'task-finished':
        setRecordingState('idle');
        const fullText = finalText + tempText;
        if (fullText) {
          onResult(fullText);
        }
        // æ¸…ç©ºçŠ¶æ€
        setTempText('');
        setFinalText('');
        setRecognizedText('');
        break;

      case 'task-failed':
      case 'error':
        setRecordingState('error');
        Alert.alert('è¯†åˆ«å¤±è´¥', event.error || 'è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•');
        setTimeout(() => setRecordingState('idle'), 1500);
        break;
    }
  };

  // å¼€å§‹å½•éŸ³
  const startRecording = async () => {
    if (!speechService.current || disabled) return;

    try {
      setRecognizedText('');
      setIsCancelling(false);

      // æŒ‰ä¸‹åŠ¨ç”»
      Animated.spring(scaleAnim, {
        toValue: 1.1,
        useNativeDriver: true,
      }).start();

      await speechService.current.startRecording(handleRecognitionEvent);
    } catch (error) {
      console.error('[VoiceInput] Start recording failed:', error);
      Alert.alert('é”™è¯¯', 'æ— æ³•å¼€å§‹å½•éŸ³ï¼Œè¯·æ£€æŸ¥éº¦å…‹é£æƒé™');
      setRecordingState('idle');
      scaleAnim.setValue(1);
    }
  };

  // åœæ­¢å½•éŸ³
  const stopRecording = async () => {
    if (!speechService.current) return;

    try {
      // æ¾å¼€åŠ¨ç”»
      Animated.spring(scaleAnim, {
        toValue: 1,
        useNativeDriver: true,
      }).start();

      if (isCancelling) {
        await speechService.current.cancelRecording();
        setRecognizedText('');
        setRecordingState('idle');
      } else {
        setRecordingState('processing');
        await speechService.current.stopRecording();
      }
    } catch (error) {
      console.error('[VoiceInput] Stop recording failed:', error);
      setRecordingState('idle');
    }
  };

  // å–æ¶ˆå½•éŸ³
  const cancelRecording = async () => {
    if (!speechService.current) return;

    setIsCancelling(true);
    await speechService.current.cancelRecording();
    setRecognizedText('');
    setRecordingState('idle');
    scaleAnim.setValue(1);
    slideAnim.setValue(0);
  };

  // æ‰‹åŠ¿å¤„ç†
  const panResponder = useRef(
    PanResponder.create({
      onStartShouldSetPanResponder: () => true,
      onMoveShouldSetPanResponder: () => true,

      onPanResponderGrant: () => {
        startRecording();
      },

      onPanResponderMove: (_, gestureState) => {
        const { dy } = gestureState;
        slideAnim.setValue(dy);

        // ä¸Šæ»‘è¶…è¿‡é˜ˆå€¼ï¼Œæ˜¾ç¤ºå–æ¶ˆæç¤º
        if (-dy > CANCEL_THRESHOLD && !isCancelling) {
          setIsCancelling(true);
        } else if (-dy <= CANCEL_THRESHOLD && isCancelling) {
          setIsCancelling(false);
        }
      },

      onPanResponderRelease: (_, gestureState) => {
        const { dy } = gestureState;
        slideAnim.setValue(0);

        // å¦‚æœä¸Šæ»‘è¶…è¿‡é˜ˆå€¼ï¼Œå–æ¶ˆå½•éŸ³
        if (-dy > CANCEL_THRESHOLD) {
          cancelRecording();
        } else {
          stopRecording();
        }
      },
    })
  ).current;

  // çŠ¶æ€æç¤º
  const getStatusHint = () => {
    if (isCancelling) return '';
    switch (recordingState) {
      case 'connecting':
        return 'è¿æ¥ä¸­...';
      case 'recording':
        return (finalText || tempText) ? '' : 'æ­£åœ¨è†å¬...';
      case 'processing':
        return 'å¤„ç†ä¸­...';
      case 'error':
        return 'è¯†åˆ«å¤±è´¥';
      default:
        return '';
    }
  };

  const isActive = recordingState !== 'idle';

  return (
    <View style={styles.container}>
      {/* å½•éŸ³æç¤ºæµ®å±‚ */}
      {isActive && (
        <View style={styles.overlay}>
          <View style={[
            styles.statusCard,
            isCancelling && styles.statusCardCancel
          ]}>
            {/* å–æ¶ˆåŒºåŸŸæç¤º */}
            {isCancelling ? (
              <>
                <Text style={styles.cancelIcon}>ğŸš«</Text>
                <Text style={styles.statusTextLarge}>æ¾å¼€å–æ¶ˆ</Text>
              </>
            ) : (
              <>
                {/* å½•éŸ³æ³¢å½¢åŠ¨ç”» */}
                <Animated.View style={[
                  styles.waveform,
                  { transform: [{ scale: pulseAnim }] }
                ]}>
                  <View style={styles.waveBar} />
                  <View style={[styles.waveBar, styles.waveBarMid]} />
                  <View style={styles.waveBar} />
                </Animated.View>

                {/* å®æ—¶è¯†åˆ«æ–‡æœ¬æ˜¾ç¤º */}
                {(finalText || tempText) ? (
                  <View style={styles.textContainer}>
                    {/* ç¡®è®¤æ–‡æœ¬ï¼ˆé»‘è‰²ï¼‰ */}
                    {finalText && (
                      <Text style={styles.finalText}>{finalText}</Text>
                    )}
                    {/* ä¸´æ—¶æ–‡æœ¬ï¼ˆç°è‰²ï¼‰ */}
                    {tempText && (
                      <Text style={styles.tempText}>{tempText}</Text>
                    )}
                  </View>
                ) : (
                  /* çŠ¶æ€æç¤º */
                  <Text style={styles.statusText}>{getStatusHint()}</Text>
                )}

                {/* åº•éƒ¨æç¤º */}
                {recordingState === 'recording' && (
                  <Text style={styles.hintText}>ä¸Šæ»‘å–æ¶ˆ</Text>
                )}
              </>
            )}
          </View>
        </View>
      )}

      {/* è¯­éŸ³è¾“å…¥æŒ‰é’® */}
      <Animated.View
        style={[
          styles.buttonWrapper,
          {
            transform: [
              { scale: scaleAnim },
              { translateY: slideAnim },
            ],
          },
        ]}
        {...panResponder.panHandlers}
      >
        <TouchableOpacity
          style={[
            styles.button,
            isActive && styles.buttonActive,
            isCancelling && styles.buttonCancel,
            disabled && styles.buttonDisabled,
          ]}
          activeOpacity={1}
          disabled={disabled}
        >
          <Text style={styles.buttonIcon}>
            {recordingState === 'recording' ? 'ğŸ¤' : 'ğŸ™ï¸'}
          </Text>
        </TouchableOpacity>
      </Animated.View>
    </View>
  );
}

const styles = StyleSheet.create({
  container: {
    position: 'relative',
  },
  overlay: {
    position: 'absolute',
    bottom: 80,
    left: 0,
    right: 0,
    alignItems: 'center',
    zIndex: 999,
  },
  statusCard: {
    backgroundColor: 'rgba(15, 23, 42, 0.95)',
    borderRadius: 20,
    paddingHorizontal: 24,
    paddingVertical: 20,
    minWidth: 200,
    maxWidth: SCREEN_WIDTH * 0.8,
    alignItems: 'center',
    shadowColor: '#000',
    shadowOffset: { width: 0, height: 4 },
    shadowOpacity: 0.3,
    shadowRadius: 12,
    elevation: 8,
  },
  statusCardCancel: {
    backgroundColor: 'rgba(239, 68, 68, 0.95)',
  },
  cancelIcon: {
    fontSize: 48,
    marginBottom: 8,
  },
  statusTextLarge: {
    fontSize: 18,
    fontWeight: '700',
    color: 'white',
    fontFamily: 'SF Pro Display',
  },
  waveform: {
    flexDirection: 'row',
    alignItems: 'center',
    gap: 4,
    marginBottom: 12,
  },
  waveBar: {
    width: 4,
    height: 24,
    backgroundColor: '#0EA5E9',
    borderRadius: 2,
  },
  waveBarMid: {
    height: 36,
  },
  statusText: {
    fontSize: 16,
    fontWeight: '600',
    color: 'white',
    textAlign: 'center',
    fontFamily: 'SF Pro Text',
    marginBottom: 4,
  },
  hintText: {
    fontSize: 13,
    color: 'rgba(255, 255, 255, 0.7)',
    fontFamily: 'SF Pro Text',
  },
  textContainer: {
    flexDirection: 'row',
    flexWrap: 'wrap',
    alignItems: 'center',
    justifyContent: 'center',
    marginBottom: 8,
    maxWidth: SCREEN_WIDTH * 0.7,
  },
  finalText: {
    fontSize: 18,
    fontWeight: '600',
    color: '#FFFFFF', // é»‘è‰²ï¼ˆç¡®è®¤æ–‡æœ¬ï¼‰
    fontFamily: 'SF Pro Text',
    lineHeight: 24,
  },
  tempText: {
    fontSize: 18,
    fontWeight: '400',
    color: 'rgba(255, 255, 255, 0.5)', // ç°è‰²ï¼ˆä¸´æ—¶æ–‡æœ¬ï¼‰
    fontFamily: 'SF Pro Text',
    lineHeight: 24,
    fontStyle: 'italic',
  },
  buttonWrapper: {
    alignItems: 'center',
    justifyContent: 'center',
  },
  button: {
    width: 56,
    height: 56,
    borderRadius: 28,
    backgroundColor: '#0EA5E9',
    alignItems: 'center',
    justifyContent: 'center',
    shadowColor: '#0EA5E9',
    shadowOffset: { width: 0, height: 4 },
    shadowOpacity: 0.3,
    shadowRadius: 8,
    elevation: 4,
  },
  buttonActive: {
    backgroundColor: '#EF4444',
    shadowColor: '#EF4444',
  },
  buttonCancel: {
    backgroundColor: '#6B7280',
    shadowColor: '#6B7280',
  },
  buttonDisabled: {
    backgroundColor: '#CBD5E1',
    shadowColor: '#CBD5E1',
    opacity: 0.5,
  },
  buttonIcon: {
    fontSize: 28,
  },
});
